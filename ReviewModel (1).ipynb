{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReviewModel",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTs53B_bx1i0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install soynlp\n",
        "!pip install konlpy\n",
        "!pip install glove_python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8AU3AduleH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from konlpy.tag import Okt, Komoran\n",
        "from soynlp.utils import DoublespaceLineCorpus\n",
        "from soynlp.vectorizer import sent_to_word_contexts_matrix\n",
        "from glove import Glove\n",
        "import re\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itFRI8C9nLDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 리뷰 데이터셋\n",
        "reviews = pd.read_csv('drive/My Drive/datasets/review_final.csv')\n",
        "content = reviews['댓글내용']\n",
        "star = reviews['별점']\n",
        "\n",
        "\n",
        "# 형태소 분석기\n",
        "komoran = Komoran() # 상대적으로 많은 데이터를 대상으로 더 빠름, 더 상세히 분석\n",
        "okt = Okt() # 상대적으로 안정성이 좋음. but 사용자 사전 기능이 없다.\n",
        "\n",
        "# Komoran 은 실행 중 버그 발생 -> 임시로 Okt 채택\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPM6yC3y-W6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizing\n",
        "def tokenize(doc):\n",
        "    # 한글 자음, 모음 제거\n",
        "    doc = re.sub(pattern='([ㄱ-ㅎㅏ-ㅣ]+)', repl='', string=doc)\n",
        "    # 특수기호 제거\n",
        "    doc = re.sub(pattern='[^\\w\\s]', repl='', string=doc)\n",
        "    # norm은 정규화, stem은 근어로 표시하기를 나타냄\n",
        "    doc = okt.pos(doc, norm=True, stem=True)\n",
        "    # 명사, 형용사, 부사, 동사 채택\n",
        "    token = []\n",
        "    for i in doc:\n",
        "        if i[1] == 'Noun' or i[1] == 'Verb' or i[1] == 'Adverb' or i[1] == 'Adjective':\n",
        "          token.append(i)\n",
        "\n",
        "    return ['/'.join(t) for t in token]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmB4U8B8e5_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단어 토큰화\n",
        "X_data = [tokenize(t) for t in content]\n",
        "# 정수 인코딩\n",
        "encoder = Tokenizer(num_words=10000)\n",
        "encoder.fit_on_texts(X_data)\n",
        "X_encoded_data = encoder.texts_to_sequences(X_data)\n",
        "\n",
        "# 레이블 원-핫 인코딩\n",
        "y_encoded_data = to_categorical(star)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-PNsP0_w55Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize(sentence):\n",
        "  l = []\n",
        "  token = tokenize(sentence)\n",
        "  l.append(token)\n",
        "  result = encoder.texts_to_sequences(l)\n",
        "  return pad_sequences(result, 100)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqaV6oO_pIQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련 데이터 6만개, 테스트 데이터 2만 7천개\n",
        "X_train = X_encoded_data[:60000]\n",
        "X_test = X_encoded_data[60000:]\n",
        "y_train = y_encoded_data[:60000]\n",
        "y_test = y_encoded_data[60000:]"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05-lT5z9pldP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 각 리뷰 데이터를 동일한 길이로 패딩\n",
        "max_len = 100\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CObq2I_lk6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "d8780f3b-a998-462a-e1be-3ef42f8a7464"
      },
      "source": [
        "# LSTM 변형 버전인 GRU. LSTM 보다 간결함.\n",
        "\n",
        "vocab_size = 10000\n",
        "\n",
        "model_gru = Sequential()\n",
        "model_gru.add(Embedding(vocab_size, 100))\n",
        "model_gru.add(GRU(128))\n",
        "model_gru.add(Dense(16, activation='relu'))\n",
        "model_gru.add(Dense(6, activation='softmax'))\n",
        "\n",
        "# 조기 종료 및 체크포인트\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model_gru.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "history = model_gru.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=100, validation_split=0.2)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "480/480 [==============================] - ETA: 0s - loss: 0.7737 - acc: 0.7133\n",
            "Epoch 00001: val_acc improved from -inf to 0.74142, saving model to GRU_model.h5\n",
            "480/480 [==============================] - 111s 232ms/step - loss: 0.7737 - acc: 0.7133 - val_loss: 0.6702 - val_acc: 0.7414\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - ETA: 0s - loss: 0.6605 - acc: 0.7440\n",
            "Epoch 00002: val_acc improved from 0.74142 to 0.75092, saving model to GRU_model.h5\n",
            "480/480 [==============================] - 110s 230ms/step - loss: 0.6605 - acc: 0.7440 - val_loss: 0.6489 - val_acc: 0.7509\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - ETA: 0s - loss: 0.6293 - acc: 0.7538\n",
            "Epoch 00003: val_acc did not improve from 0.75092\n",
            "480/480 [==============================] - 111s 231ms/step - loss: 0.6293 - acc: 0.7538 - val_loss: 0.6923 - val_acc: 0.7366\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - ETA: 0s - loss: 0.6106 - acc: 0.7607\n",
            "Epoch 00004: val_acc did not improve from 0.75092\n",
            "480/480 [==============================] - 111s 232ms/step - loss: 0.6106 - acc: 0.7607 - val_loss: 0.6803 - val_acc: 0.7358\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - ETA: 0s - loss: 0.5958 - acc: 0.7661\n",
            "Epoch 00005: val_acc did not improve from 0.75092\n",
            "480/480 [==============================] - 111s 230ms/step - loss: 0.5958 - acc: 0.7661 - val_loss: 0.6657 - val_acc: 0.7456\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZl6lHdOF8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47b2aadc-4cac-4d53-c837-f026e9a4b495"
      },
      "source": [
        "model_gru.predict_classes(vectorize('평좋아서 샀는데 저는 너무 달고 느끼했어요'))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxId-97vRUKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_gru.save('drive/My Drive/datasets/gru_model.h5')"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1KfD943x-0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "baa45a9a-2ad6-4350-d183-fe9d842260f1"
      },
      "source": [
        "# Vectorize to co-occurence matrix\n",
        "x, idx2vocab = sent_to_word_contexts_matrix(\n",
        "    content,\n",
        "    windows=3,\n",
        "    min_tf=10,\n",
        "    tokenizer=tokenize,\n",
        "    dynamic_weight=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# glove (Word Embedding)\n",
        "glove = Glove(no_components=100, learning_rate=0.05, max_count=30)\n",
        "# input coo matrix 변환\n",
        "glove.fit(x.tocoo(), epochs=5, no_threads=4, verbose=True)\n",
        "\n",
        "# 사전 추가\n",
        "dictionary = {vocab:idx for idx, vocab in enumerate(idx2vocab)}\n",
        "glove.add_dictionary(dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create (word, contexts) matrix\n",
            "  - counting word frequency from 87410 sents, mem=0.909 Gb\n",
            "  - scanning (word, context) pairs from 87410 sents, mem=1.043 Gb\n",
            "  - (word, context) matrix was constructed. shape = (6006, 6006)                    \n",
            "  - done\n",
            "Performing 5 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM-I-ZR_8WUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokened(sentence):\n",
        "  return ['/'.join(x) for x in okt.pos(sentence)][0]\n",
        "\n",
        "def get_most_similar(word):\n",
        "  print(tokened(word))\n",
        "  print(glove.most_similar(tokened(word), number=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlUbqZM0r1_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "aa6b3382-723d-4fda-dea5-371e16d97317"
      },
      "source": [
        "# 유사 단어 테스트\n",
        "glove.most_similar(tokened('볶음'), number=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('오뎅/Noun', 0.8337399648625302),\n",
              " ('탕/Noun', 0.8073953231965109),\n",
              " ('샤브샤브/Noun', 0.7304645581988074),\n",
              " ('주꾸미/Noun', 0.7113417844249657),\n",
              " ('제육/Noun', 0.7101901277544247),\n",
              " ('된장/Noun', 0.7026016259594793),\n",
              " ('숙주/Noun', 0.701619828402634),\n",
              " ('샌드위치/Noun', 0.7007344901125827),\n",
              " ('찌게/Noun', 0.690310771903459)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSZmWSD92VF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove model 저장\n",
        "glove.save('drive/My Drive/datasets/glove_test.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsmRm-J2FauJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}