{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장내용 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "new_t = []\n",
    "f = open('elect_training.csv','r',encoding='utf-8-sig')\n",
    "rdf = csv.reader(f)\n",
    "\n",
    "for i in rdf:\n",
    "    new_t.append(i)\n",
    "\n",
    "len(new_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 광고성리뷰 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰에 'http'를 포함하는 링크가 있을 시 제외\n"
    "new_t = filter(lambda i: 'http' not in i[0], new_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Text: 2/Number 개월/Noun 돼다/Verb 특별하다/Adjective 충격/Noun 도/Josa 없다/Adjective 아침/Noun...>\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def modify(text):\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)' #한글 자모음 제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '[^\\w\\s]' #특수기호 제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    return text\n",
    "\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in okt.pos(doc,norm=True,stem=True)]\n",
    "\n",
    "\n",
    "\n",
    "training = [(tokenize(modify(row[0])),row[1]) for row in new_t]#[('단어/형태',...,0 or 1)]\n",
    "\n",
    "print()\n",
    "token = [t for d in training for t in d[0]] #단어들만 따로 모음\n",
    "text = nltk.Text(token)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최빈값 추출 및 단어 빈도 수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = [f[0] for f in text.vocab().most_common(2500)] \n",
    "\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x = [term_frequency(d) for d,_ in training]\n",
    "\n",
    "train_x2 = [term_frequency(d) for d,_ in training]\n",
    "train_x = []\n",
    "\n",
    "for d in train_x2:\n",
    "    train_x.append([i/sum(d) for i in d])\n",
    "\n",
    "train_y = [c for _,c in training]#[(나/noun,는/josa...,1),(그/noun..,1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.asarray(train_x).astype('float32')\n",
    "#x_test = np.asarray(test_x).astype('float32')\n",
    "y_train = np.asarray(train_y).astype('float32')\n",
    "#y_test = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "472/472 [==============================] - 1s 2ms/sample - loss: 0.6930 - binary_accuracy: 0.5042\n",
      "Epoch 2/200\n",
      "472/472 [==============================] - 0s 243us/sample - loss: 0.6808 - binary_accuracy: 0.8517\n",
      "Epoch 3/200\n",
      "472/472 [==============================] - 0s 213us/sample - loss: 0.6594 - binary_accuracy: 0.7500\n",
      "Epoch 4/200\n",
      "472/472 [==============================] - 0s 229us/sample - loss: 0.6294 - binary_accuracy: 0.9301\n",
      "Epoch 5/200\n",
      "472/472 [==============================] - 0s 181us/sample - loss: 0.5935 - binary_accuracy: 0.7945\n",
      "Epoch 6/200\n",
      "472/472 [==============================] - 0s 189us/sample - loss: 0.5620 - binary_accuracy: 0.8814\n",
      "Epoch 7/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.5267 - binary_accuracy: 0.8136\n",
      "Epoch 8/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.4822 - binary_accuracy: 0.9449\n",
      "Epoch 9/200\n",
      "472/472 [==============================] - 0s 136us/sample - loss: 0.4390 - binary_accuracy: 0.9216\n",
      "Epoch 10/200\n",
      "472/472 [==============================] - 0s 149us/sample - loss: 0.4007 - binary_accuracy: 0.9661\n",
      "Epoch 11/200\n",
      "472/472 [==============================] - 0s 153us/sample - loss: 0.3689 - binary_accuracy: 0.9449\n",
      "Epoch 12/200\n",
      "472/472 [==============================] - 0s 392us/sample - loss: 0.3399 - binary_accuracy: 0.9640\n",
      "Epoch 13/200\n",
      "472/472 [==============================] - 0s 214us/sample - loss: 0.3145 - binary_accuracy: 0.9534\n",
      "Epoch 14/200\n",
      "472/472 [==============================] - 0s 144us/sample - loss: 0.2866 - binary_accuracy: 0.9661\n",
      "Epoch 15/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.2617 - binary_accuracy: 0.9767\n",
      "Epoch 16/200\n",
      "472/472 [==============================] - 0s 147us/sample - loss: 0.2377 - binary_accuracy: 0.9746\n",
      "Epoch 17/200\n",
      "472/472 [==============================] - 0s 148us/sample - loss: 0.2175 - binary_accuracy: 0.9852\n",
      "Epoch 18/200\n",
      "472/472 [==============================] - 0s 155us/sample - loss: 0.1991 - binary_accuracy: 0.9831\n",
      "Epoch 19/200\n",
      "472/472 [==============================] - 0s 151us/sample - loss: 0.1833 - binary_accuracy: 0.9915\n",
      "Epoch 20/200\n",
      "472/472 [==============================] - 0s 128us/sample - loss: 0.1689 - binary_accuracy: 0.9852\n",
      "Epoch 21/200\n",
      "472/472 [==============================] - 0s 133us/sample - loss: 0.1562 - binary_accuracy: 0.9936\n",
      "Epoch 22/200\n",
      "472/472 [==============================] - 0s 180us/sample - loss: 0.1446 - binary_accuracy: 0.9894\n",
      "Epoch 23/200\n",
      "472/472 [==============================] - 0s 134us/sample - loss: 0.1340 - binary_accuracy: 0.9936\n",
      "Epoch 24/200\n",
      "472/472 [==============================] - 0s 134us/sample - loss: 0.1240 - binary_accuracy: 0.9915\n",
      "Epoch 25/200\n",
      "472/472 [==============================] - 0s 129us/sample - loss: 0.1147 - binary_accuracy: 0.9936\n",
      "Epoch 26/200\n",
      "472/472 [==============================] - 0s 124us/sample - loss: 0.1059 - binary_accuracy: 0.9915\n",
      "Epoch 27/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0978 - binary_accuracy: 0.9936\n",
      "Epoch 28/200\n",
      "472/472 [==============================] - 0s 129us/sample - loss: 0.0902 - binary_accuracy: 0.9936\n",
      "Epoch 29/200\n",
      "472/472 [==============================] - 0s 144us/sample - loss: 0.0833 - binary_accuracy: 0.9936\n",
      "Epoch 30/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0770 - binary_accuracy: 0.9936\n",
      "Epoch 31/200\n",
      "472/472 [==============================] - 0s 154us/sample - loss: 0.0713 - binary_accuracy: 0.9936\n",
      "Epoch 32/200\n",
      "472/472 [==============================] - 0s 138us/sample - loss: 0.0663 - binary_accuracy: 0.9936\n",
      "Epoch 33/200\n",
      "472/472 [==============================] - 0s 124us/sample - loss: 0.0617 - binary_accuracy: 0.9958\n",
      "Epoch 34/200\n",
      "472/472 [==============================] - 0s 126us/sample - loss: 0.0575 - binary_accuracy: 0.9936\n",
      "Epoch 35/200\n",
      "472/472 [==============================] - 0s 130us/sample - loss: 0.0536 - binary_accuracy: 0.9958\n",
      "Epoch 36/200\n",
      "472/472 [==============================] - 0s 127us/sample - loss: 0.0501 - binary_accuracy: 0.9958\n",
      "Epoch 37/200\n",
      "472/472 [==============================] - 0s 128us/sample - loss: 0.0469 - binary_accuracy: 0.9958\n",
      "Epoch 38/200\n",
      "472/472 [==============================] - 0s 128us/sample - loss: 0.0439 - binary_accuracy: 0.9958\n",
      "Epoch 39/200\n",
      "472/472 [==============================] - 0s 122us/sample - loss: 0.0411 - binary_accuracy: 0.9958\n",
      "Epoch 40/200\n",
      "472/472 [==============================] - 0s 132us/sample - loss: 0.0386 - binary_accuracy: 0.9958\n",
      "Epoch 41/200\n",
      "472/472 [==============================] - 0s 410us/sample - loss: 0.0362 - binary_accuracy: 0.9958\n",
      "Epoch 42/200\n",
      "472/472 [==============================] - 0s 139us/sample - loss: 0.0339 - binary_accuracy: 0.9958\n",
      "Epoch 43/200\n",
      "472/472 [==============================] - 0s 132us/sample - loss: 0.0318 - binary_accuracy: 0.9958\n",
      "Epoch 44/200\n",
      "472/472 [==============================] - 0s 133us/sample - loss: 0.0299 - binary_accuracy: 0.9958\n",
      "Epoch 45/200\n",
      "472/472 [==============================] - 0s 134us/sample - loss: 0.0283 - binary_accuracy: 0.9958\n",
      "Epoch 46/200\n",
      "472/472 [==============================] - 0s 128us/sample - loss: 0.0269 - binary_accuracy: 0.9958\n",
      "Epoch 47/200\n",
      "472/472 [==============================] - 0s 124us/sample - loss: 0.0255 - binary_accuracy: 0.9958\n",
      "Epoch 48/200\n",
      "472/472 [==============================] - 0s 125us/sample - loss: 0.0244 - binary_accuracy: 0.9958\n",
      "Epoch 49/200\n",
      "472/472 [==============================] - 0s 120us/sample - loss: 0.0233 - binary_accuracy: 0.9958\n",
      "Epoch 50/200\n",
      "472/472 [==============================] - 0s 127us/sample - loss: 0.0223 - binary_accuracy: 0.9958\n",
      "Epoch 51/200\n",
      "472/472 [==============================] - 0s 119us/sample - loss: 0.0212 - binary_accuracy: 0.9958\n",
      "Epoch 52/200\n",
      "472/472 [==============================] - 0s 120us/sample - loss: 0.0203 - binary_accuracy: 0.9958\n",
      "Epoch 53/200\n",
      "472/472 [==============================] - 0s 132us/sample - loss: 0.0194 - binary_accuracy: 0.9958\n",
      "Epoch 54/200\n",
      "472/472 [==============================] - 0s 147us/sample - loss: 0.0186 - binary_accuracy: 0.9958\n",
      "Epoch 55/200\n",
      "472/472 [==============================] - 0s 147us/sample - loss: 0.0177 - binary_accuracy: 0.9958\n",
      "Epoch 56/200\n",
      "472/472 [==============================] - 0s 149us/sample - loss: 0.0171 - binary_accuracy: 0.9958\n",
      "Epoch 57/200\n",
      "472/472 [==============================] - 0s 148us/sample - loss: 0.0164 - binary_accuracy: 0.9958\n",
      "Epoch 58/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0158 - binary_accuracy: 0.9958\n",
      "Epoch 59/200\n",
      "472/472 [==============================] - 0s 161us/sample - loss: 0.0153 - binary_accuracy: 0.9958\n",
      "Epoch 60/200\n",
      "472/472 [==============================] - 0s 155us/sample - loss: 0.0149 - binary_accuracy: 0.9958\n",
      "Epoch 61/200\n",
      "472/472 [==============================] - 0s 153us/sample - loss: 0.0144 - binary_accuracy: 0.9958\n",
      "Epoch 62/200\n",
      "472/472 [==============================] - 0s 168us/sample - loss: 0.0141 - binary_accuracy: 0.9958\n",
      "Epoch 63/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0138 - binary_accuracy: 0.9958\n",
      "Epoch 64/200\n",
      "472/472 [==============================] - 0s 160us/sample - loss: 0.0135 - binary_accuracy: 0.9958\n",
      "Epoch 65/200\n",
      "472/472 [==============================] - 0s 171us/sample - loss: 0.0132 - binary_accuracy: 0.9958\n",
      "Epoch 66/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0130 - binary_accuracy: 0.9958\n",
      "Epoch 67/200\n",
      "472/472 [==============================] - 0s 179us/sample - loss: 0.0127 - binary_accuracy: 0.9958\n",
      "Epoch 68/200\n",
      "472/472 [==============================] - 0s 183us/sample - loss: 0.0125 - binary_accuracy: 0.9958\n",
      "Epoch 69/200\n",
      "472/472 [==============================] - 0s 376us/sample - loss: 0.0122 - binary_accuracy: 0.9958\n",
      "Epoch 70/200\n",
      "472/472 [==============================] - 0s 192us/sample - loss: 0.0120 - binary_accuracy: 0.9958\n",
      "Epoch 71/200\n",
      "472/472 [==============================] - 0s 177us/sample - loss: 0.0117 - binary_accuracy: 0.9958\n",
      "Epoch 72/200\n",
      "472/472 [==============================] - 0s 177us/sample - loss: 0.0115 - binary_accuracy: 0.9958\n",
      "Epoch 73/200\n",
      "472/472 [==============================] - 0s 173us/sample - loss: 0.0112 - binary_accuracy: 0.9958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "472/472 [==============================] - 0s 168us/sample - loss: 0.0111 - binary_accuracy: 0.9958\n",
      "Epoch 75/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0109 - binary_accuracy: 0.9958\n",
      "Epoch 76/200\n",
      "472/472 [==============================] - 0s 180us/sample - loss: 0.0108 - binary_accuracy: 0.9958\n",
      "Epoch 77/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0106 - binary_accuracy: 0.9958\n",
      "Epoch 78/200\n",
      "472/472 [==============================] - 0s 181us/sample - loss: 0.0106 - binary_accuracy: 0.9958\n",
      "Epoch 79/200\n",
      "472/472 [==============================] - 0s 176us/sample - loss: 0.0105 - binary_accuracy: 0.9958\n",
      "Epoch 80/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0105 - binary_accuracy: 0.9958\n",
      "Epoch 81/200\n",
      "472/472 [==============================] - 0s 171us/sample - loss: 0.0103 - binary_accuracy: 0.9958\n",
      "Epoch 82/200\n",
      "472/472 [==============================] - 0s 175us/sample - loss: 0.0103 - binary_accuracy: 0.9958\n",
      "Epoch 83/200\n",
      "472/472 [==============================] - 0s 182us/sample - loss: 0.0102 - binary_accuracy: 0.9958\n",
      "Epoch 84/200\n",
      "472/472 [==============================] - 0s 192us/sample - loss: 0.0101 - binary_accuracy: 0.9958\n",
      "Epoch 85/200\n",
      "472/472 [==============================] - 0s 189us/sample - loss: 0.0099 - binary_accuracy: 0.9958\n",
      "Epoch 86/200\n",
      "472/472 [==============================] - 0s 181us/sample - loss: 0.0099 - binary_accuracy: 0.9958\n",
      "Epoch 87/200\n",
      "472/472 [==============================] - 0s 176us/sample - loss: 0.0097 - binary_accuracy: 0.9958\n",
      "Epoch 88/200\n",
      "472/472 [==============================] - 0s 170us/sample - loss: 0.0097 - binary_accuracy: 0.9958\n",
      "Epoch 89/200\n",
      "472/472 [==============================] - 0s 187us/sample - loss: 0.0096 - binary_accuracy: 0.9958\n",
      "Epoch 90/200\n",
      "472/472 [==============================] - 0s 179us/sample - loss: 0.0096 - binary_accuracy: 0.9958\n",
      "Epoch 91/200\n",
      "472/472 [==============================] - 0s 176us/sample - loss: 0.0095 - binary_accuracy: 0.9958\n",
      "Epoch 92/200\n",
      "472/472 [==============================] - 0s 463us/sample - loss: 0.0095 - binary_accuracy: 0.9958\n",
      "Epoch 93/200\n",
      "472/472 [==============================] - 0s 205us/sample - loss: 0.0095 - binary_accuracy: 0.9958\n",
      "Epoch 94/200\n",
      "472/472 [==============================] - 0s 149us/sample - loss: 0.0095 - binary_accuracy: 0.9958\n",
      "Epoch 95/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0094 - binary_accuracy: 0.9958\n",
      "Epoch 96/200\n",
      "472/472 [==============================] - 0s 164us/sample - loss: 0.0095 - binary_accuracy: 0.9958\n",
      "Epoch 97/200\n",
      "472/472 [==============================] - 0s 168us/sample - loss: 0.0093 - binary_accuracy: 0.9958\n",
      "Epoch 98/200\n",
      "472/472 [==============================] - 0s 162us/sample - loss: 0.0094 - binary_accuracy: 0.9958\n",
      "Epoch 99/200\n",
      "472/472 [==============================] - 0s 165us/sample - loss: 0.0092 - binary_accuracy: 0.9958\n",
      "Epoch 100/200\n",
      "472/472 [==============================] - 0s 165us/sample - loss: 0.0092 - binary_accuracy: 0.9958\n",
      "Epoch 101/200\n",
      "472/472 [==============================] - 0s 165us/sample - loss: 0.0091 - binary_accuracy: 0.9958\n",
      "Epoch 102/200\n",
      "472/472 [==============================] - 0s 180us/sample - loss: 0.0092 - binary_accuracy: 0.9958\n",
      "Epoch 103/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0091 - binary_accuracy: 0.9958\n",
      "Epoch 104/200\n",
      "472/472 [==============================] - 0s 168us/sample - loss: 0.0092 - binary_accuracy: 0.9958\n",
      "Epoch 105/200\n",
      "472/472 [==============================] - 0s 174us/sample - loss: 0.0091 - binary_accuracy: 0.9958\n",
      "Epoch 106/200\n",
      "472/472 [==============================] - 0s 175us/sample - loss: 0.0092 - binary_accuracy: 0.9958\n",
      "Epoch 107/200\n",
      "472/472 [==============================] - 0s 168us/sample - loss: 0.0091 - binary_accuracy: 0.9958\n",
      "Epoch 108/200\n",
      "472/472 [==============================] - 0s 172us/sample - loss: 0.0092 - binary_accuracy: 0.9958\n",
      "Epoch 109/200\n",
      "472/472 [==============================] - 0s 157us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 110/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0091 - binary_accuracy: 0.9958\n",
      "Epoch 111/200\n",
      "472/472 [==============================] - 0s 157us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 112/200\n",
      "472/472 [==============================] - 0s 172us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 113/200\n",
      "472/472 [==============================] - 0s 162us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 114/200\n",
      "472/472 [==============================] - 0s 153us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 115/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 116/200\n",
      "472/472 [==============================] - 0s 162us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 117/200\n",
      "472/472 [==============================] - 0s 422us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 118/200\n",
      "472/472 [==============================] - 0s 159us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 119/200\n",
      "472/472 [==============================] - 0s 149us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 120/200\n",
      "472/472 [==============================] - 0s 170us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 121/200\n",
      "472/472 [==============================] - 0s 159us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 122/200\n",
      "472/472 [==============================] - 0s 157us/sample - loss: 0.0090 - binary_accuracy: 0.9958\n",
      "Epoch 123/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 124/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 125/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 126/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 127/200\n",
      "472/472 [==============================] - 0s 155us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 128/200\n",
      "472/472 [==============================] - 0s 170us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 129/200\n",
      "472/472 [==============================] - 0s 173us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 130/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 131/200\n",
      "472/472 [==============================] - 0s 160us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 132/200\n",
      "472/472 [==============================] - 0s 179us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 133/200\n",
      "472/472 [==============================] - 0s 162us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 134/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0089 - binary_accuracy: 0.9958\n",
      "Epoch 135/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 136/200\n",
      "472/472 [==============================] - 0s 174us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 137/200\n",
      "472/472 [==============================] - 0s 153us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 138/200\n",
      "472/472 [==============================] - 0s 165us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 139/200\n",
      "472/472 [==============================] - 0s 180us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 140/200\n",
      "472/472 [==============================] - 0s 177us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 141/200\n",
      "472/472 [==============================] - 0s 170us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 142/200\n",
      "472/472 [==============================] - 0s 484us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 143/200\n",
      "472/472 [==============================] - 0s 162us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 144/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 145/200\n",
      "472/472 [==============================] - 0s 164us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472/472 [==============================] - 0s 164us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 147/200\n",
      "472/472 [==============================] - 0s 157us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 148/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 149/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 150/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 151/200\n",
      "472/472 [==============================] - 0s 157us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 152/200\n",
      "472/472 [==============================] - 0s 161us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 153/200\n",
      "472/472 [==============================] - 0s 149us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 154/200\n",
      "472/472 [==============================] - 0s 151us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 155/200\n",
      "472/472 [==============================] - 0s 152us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 156/200\n",
      "472/472 [==============================] - 0s 148us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 157/200\n",
      "472/472 [==============================] - 0s 148us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 158/200\n",
      "472/472 [==============================] - 0s 149us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 159/200\n",
      "472/472 [==============================] - 0s 143us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 160/200\n",
      "472/472 [==============================] - 0s 163us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 161/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 162/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0088 - binary_accuracy: 0.9958\n",
      "Epoch 163/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 164/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 165/200\n",
      "472/472 [==============================] - 0s 155us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 166/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 167/200\n",
      "472/472 [==============================] - 0s 482us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 168/200\n",
      "472/472 [==============================] - 0s 159us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 169/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 170/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 171/200\n",
      "472/472 [==============================] - 0s 160us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 172/200\n",
      "472/472 [==============================] - 0s 169us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 173/200\n",
      "472/472 [==============================] - 0s 158us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 174/200\n",
      "472/472 [==============================] - 0s 159us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 175/200\n",
      "472/472 [==============================] - 0s 188us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 176/200\n",
      "472/472 [==============================] - 0s 159us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 177/200\n",
      "472/472 [==============================] - 0s 185us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 178/200\n",
      "472/472 [==============================] - 0s 164us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 179/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 180/200\n",
      "472/472 [==============================] - 0s 161us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 181/200\n",
      "472/472 [==============================] - 0s 162us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 182/200\n",
      "472/472 [==============================] - 0s 153us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 183/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 184/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 185/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 186/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 187/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 188/200\n",
      "472/472 [==============================] - 0s 156us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 189/200\n",
      "472/472 [==============================] - 0s 166us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 190/200\n",
      "472/472 [==============================] - 0s 168us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 191/200\n",
      "472/472 [==============================] - 0s 172us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 192/200\n",
      "472/472 [==============================] - 0s 491us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 193/200\n",
      "472/472 [==============================] - 0s 173us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 194/200\n",
      "472/472 [==============================] - 0s 173us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 195/200\n",
      "472/472 [==============================] - 0s 174us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 196/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 197/200\n",
      "472/472 [==============================] - 0s 169us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 198/200\n",
      "472/472 [==============================] - 0s 169us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n",
      "Epoch 199/200\n",
      "472/472 [==============================] - 0s 185us/sample - loss: 0.0086 - binary_accuracy: 0.9958\n",
      "Epoch 200/200\n",
      "472/472 [==============================] - 0s 167us/sample - loss: 0.0087 - binary_accuracy: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b21efcd90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1200,activation='relu',input_shape=(2500,)))#실제 쓸 단어갯수\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),loss = losses.binary_crossentropy,metrics=[metrics.binary_accuracy])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=200,batch_size=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.asarray(tf).astype('float32'),axis=0)\n",
    "    score = float(model.predict(data))\n",
    "    #print(score)\n",
    "    if(score>0.5):\n",
    "        #print(\"[{}]는 {:.2f}%확률로 만족 리뷰입니다.\".format(review,score*100))\n",
    "        return score\n",
    "    else:\n",
    "        #print(\"[{}]는 {:.2f}%확률로 불만족 리뷰입니다.\".format(review,(1-score)*100))\n",
    "        return -(1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가성비': 27, 'as': 8, '사은품': 17, '배송': 0, '성능': 40}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '배송은 빠른데 as는 별로에요 사은품은 많이줬고 가성비는 그저 그렇네요 성능은 좋아요'\n",
    "dic = {}\n",
    "keyword = ['가성비','as','사은품','배송','성능']\n",
    "for i in keyword:\n",
    "    num = s.find(i)\n",
    "    dic[i] = num\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가성비', 'as', '사은품', '배송', '성능']\n"
     ]
    }
   ],
   "source": [
    "order = []\n",
    "for i in dic:\n",
    "    order.append(i)\n",
    "    \n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as', '가성비', '사은품', '배송', '성능']\n",
      "['as', '가성비', '사은품', '배송', '성능']\n",
      "['배송', '가성비', '사은품', 'as', '성능']\n",
      "['배송', '가성비', '사은품', 'as', '성능']\n",
      "['배송', '사은품', '가성비', 'as', '성능']\n",
      "['배송', 'as', '가성비', '사은품', '성능']\n",
      "['배송', 'as', '가성비', '사은품', '성능']\n",
      "['배송', 'as', '사은품', '가성비', '성능']\n",
      "['배송', 'as', '사은품', '가성비', '성능']\n",
      "['배송', 'as', '사은품', '가성비', '성능']\n",
      "['배송', 'as', '사은품', '가성비', '성능']\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(order)-1):\n",
    "    for k in range(j+1,len(order)):\n",
    "        if dic[order[j]]>dic[order[k]]:\n",
    "            temp = order[j]\n",
    "            order[j] = order[k]\n",
    "            order[k] = temp\n",
    "            print(order)\n",
    "        else:\n",
    "            print(order)\n",
    "            \n",
    "print(order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[배송은 빠른데 ]는 99.08%확률로 만족 리뷰입니다.\n",
      "[as는 별로에요 ]는 100.00%확률로 불만족 리뷰입니다.\n",
      "[사은품은 많이줬고 ]는 100.00%확률로 만족 리뷰입니다.\n",
      "[가성비는 그저 그렇네요 ]는 100.00%확률로 불만족 리뷰입니다.\n",
      "[성능은 좋아요]는 100.00%확률로 만족 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(order)):\n",
    "    if i != len(order)-1:\n",
    "        line = s[dic[order[i]]:dic[order[i+1]]]\n",
    "    else:\n",
    "        line = s[dic[order[i]]:]\n",
    "    predict(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "score = {'가성비':0,'as':0,'배송':0,'성능':0} #총점\n",
    "f = open('LG전자 2019 울트라PC.csv','r',encoding='utf-8-sig')\n",
    "f2 = open('LG전자 2019 울트라PC 수정.csv','w',encoding='utf-8-sig')\n",
    "r = csv.reader(f)\n",
    "r = filter(lambda i: 'http' not in i[0], r) #댓글에 'http'를 포함하는 링크가 있을 시 제외\n"
    "w = csv.writer(f2)\n",
    "keyword = []\n",
    "new_file = []\n",
    "for i in score:\n",
    "    keyword.append(i)\n",
    "\n",
    "number = 0\n",
    "for i in r:\n",
    "    each_score = {'가성비':0,'as':0,'배송':0,'성능':0} #개별리뷰별 최상위 키워드에 대한 점수\n",
    "    empty = []\n",
    "    empty.append(i[0])\n",
    "    dic = {} #해당 리뷰 내 최상위 키워드의 인덱스 넣는부분\n",
    "    order = [] #단일 리뷰 내에서 출현한 최상위키워드를 순서대로 넣음\n",
    "    number = number + 1\n",
    "    for j in keyword: #키워드 첫 index 찾는부분\n",
    "        num = i[0].find(j)\n",
    "        dic[j] = num\n",
    "    for k in dic: #index가 -1이 아니면 order list에 넣음\n",
    "        if dic[k] !=-1:\n",
    "            order.append(k)\n",
    "            \n",
    "    for l in range(len(order)-1): #리뷰에 최상위 키워드가 출현한 순서로 list 재배열\n",
    "        for m in range(l+1,len(order)):\n",
    "            if dic[order[l]]>dic[order[m]]:\n",
    "                temp = order[l]\n",
    "                order[l] = order[m]\n",
    "                order[m] = temp\n",
    "    for n in range(len(order)): #찾은 최상위 키워드의 인덱스를 사용하여 다음 최상위 키워드 전까지 슬라이싱하고 Predict\n",
    "        if n != len(order)-1:\n",
    "            line = i[0][dic[order[n]]:dic[order[n+1]]]\n",
    "            each_score[order[n]] = predict(line)\n",
    "            score[order[n]] = score[order[n]] + predict(line)\n",
    "        else:\n",
    "            line = i[0][dic[order[n]]:]\n",
    "            each_score[order[n]] = predict(line)\n",
    "            score[order[n]] = score[order[n]] + predict(line)\n",
    "    for o in each_score: \n",
    "        empty.append(each_score[o])\n",
    "        \n",
    "    new_file.append(empty)\n",
    "    \n",
    "for line in new_file:\n",
    "    w.writerow(line)\n",
    "    \n",
    "f.close()\n",
    "f2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_score = ['LG전자 2019 울트라PC']\n",
    "for j in score:\n",
    "    sco = score[j]/number\n",
    "    last_score.append(sco)\n",
    "\n",
    "last_table.append(last_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_table = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['MSI GL시리즈 GL65 9SD',\n",
       "  0.11320754716981132,\n",
       "  0.009433962264150943,\n",
       "  0.2358490566037736,\n",
       "  0.20754716981132076],\n",
       " ['삼성전자 갤럭시북 이온',\n",
       "  0.02339986235375086,\n",
       "  0.01032346868547832,\n",
       "  0.17412250516173433,\n",
       "  0.19821059876118377],\n",
       " ['레노버 아이디어패드',\n",
       "  0.15728155339805824,\n",
       "  -0.005825242718446602,\n",
       "  0.05825242718446602,\n",
       "  0.1378640776699029],\n",
       " ['LG전자 2019 울트라PC',\n",
       "  0.20486555697823303,\n",
       "  0.008962868117797696,\n",
       "  0.13316261203585147,\n",
       "  0.14084507042253522]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드별 스코어의 가중평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = open('last_table.csv','w',encoding='utf-8-sig')\n",
    "w = csv.writer(final)\n",
    "\n",
    "for i in last_table:\n",
    "    w.writerow(i)\n",
    "    \n",
    "final.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
